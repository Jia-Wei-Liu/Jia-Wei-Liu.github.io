<html lang="en" class="jia-wei-liu.github.io"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
	
    <meta name="description" content="Jiawei Liu's Homepage">
    <meta name="author" content="Jiawei Liu">

    <title>Jiawei Liu</title>
    <link rel="icon" href="./assets/Jiawei.png">
    <!-- Bootstrap Core CSS -->
    <link href="./assets/bootstrap.min.css" rel="stylesheet" type="text/css">

	<!-- Font Awesome -->
	<link href="./assets/font-awesome.min.css" rel="stylesheet" type="text/css">
	
    <!-- Animation -->
	<link href="./assets/animate.css" rel="stylesheet">
	
    <!-- MyTemplate CSS -->
    <link href="./assets/style.css" rel="stylesheet">
	
</head>

<body data-gr-c-s-loaded="true" style="">
	<header id="header-banner">
		<nav class="navbar navbar-default navbar-fixed-top fadeIn top-nav-collapse" role="navigation">
			<div class="container">
				<!-- Brand and toggle get grouped for better mobile display -->
				<div class="navbar-header">
					<button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#dropdown-box-1">
						<span class="sr-only">Toggle navigation</span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
					</button>
					<div class="navbar-brand">
						<a href="https://jia-wei-liu.github.io#">Homepage</a>
					</div>
				</div>
				
				<!-- Collect the nav links and other content for toggling -->
				<div class="collapse navbar-collapse navbar-right" id="dropdown-box-1">
					
					<ul class="nav navbar-nav">
						<li class="active"><a href="https://jia-wei-liu.github.io#home">HOME</a></li>
						<li><a href="https://jia-wei-liu.github.io#aboutus">ABOUT</a></li>
						<li><a href="https://jia-wei-liu.github.io#news">NEWS</a></li>
						<li><a href="https://jia-wei-liu.github.io#publications">SELECTED PUBLICATIONS</a></li>
						<li><a href="https://jia-wei-liu.github.io#awards">SELECTED AWARDS</a></li>
                        <li><a href="https://jia-wei-liu.github.io#academic_services">ACADEMIC ATTENDANCE & SERVICES</a></li>
					</ul>
					
				</div>
				
			</div> <!-- /.container -->
		</nav> <!-- /.nav -->
	</header>
		
	<!-- banner -->
    <section class="banner" id="home">
		<div class="container" style="margin-top:20px">
			<div class="slogan">
				<h2>JIAWEI LIU</h2>
				<h4>THINK DEEP AND WORK HARD.</h4>
			</div>
			
			<div class="btn-circle-scroll fadeIn">
				<a href="https://jia-wei-liu.github.io#section-footer" class="btn-circle">
					<i class="fa fa-angle-double-down animated"></i>
				</a>
			</div>
			
		</div>
    </section>
	<!-- /.banner -->

	<!-- aboutus -->
    <section class="aboutus" id="aboutus">
		<div class="container">
			<div class="row">
				<div class="col-lg-12 col-md-12 col-sm-12 col-xs-12">
					<div class="wow bounceInLeft animated animated" data-wow-delay="0.1s" style="visibility: visible;-webkit-animation-delay: 0.1s; -moz-animation-delay: 0.1s; animation-delay: 0.1s;"> 
						<h2>About ME</h2> 
					</div>
					<div class="col-sm-3 col-md-3 col-lg-2" style="margin-left:10px; margin-top:15px;">
						<div class="img-aboutus">
							<div class="wow fadeIn animated animated" data-wow-delay="0.2s" style="visibility: visible;-webkit-animation-delay: 0.2s; -moz-animation-delay: 0.2s; animation-delay: 0.2s;">
								<img src="./assets/Jiawei.png" width="250px" alt="" class="img-responsive img-rounded">
							</div>
						</div>
					</div>							
					<div class="col-sm-9 col-md-9 col-lg-8">
						<h3>
							Jiawei Liu (刘佳玮)
						</h3>
						<p></p>
							<img src="./assets/email.jpg" width="15" height="15" alt=""><a href="mailto:jiawei.liu@u.nus.edu"> jiawei.liu@u.nus.edu</a> <br> 
							<img src="./assets/google_scholar.png" width="15" height="15" alt=""><a href="https://scholar.google.com/citations?user=stQQf7wAAAAJ"> Google Scholar</a> <br> 
                            <img src="./assets/linkedin.png" width="16" height="16" alt=""><a href="https://sg.linkedin.com/in/jiawei-liu-0a70b9187"> Linkedin</a> <br> 
							<img src="./assets/github.png" width="15" height="15" alt=""><a href="https://github.com/Jia-Wei-Liu"> Github</a> <br> 
						<p></p>
						<p>
							Hello! I am a Research Scientist at Meta FAIR. I obtained my PhD in Computer Science from National University of Singapore, advised by Prof. Mike Zheng Shou and Prof. Jussi Keppo. I am working on <strong>Multi-Media 3D/4D/Video Generation and Perception</strong>.
						</p>				
						
					</div>
				</div>				
			</div>
		</div>
	</section>
	<!-- /.aboutus -->
	<!-- news -->
	
	<section class="testimonials" id="news">
		<div class="container">
			<div class="wow bounceInLeft animated animated" data-wow-delay="0.1s" style="visibility: visible;-webkit-animation-delay: 0.1s; -moz-animation-delay: 0.1s; animation-delay: 0.1s;"> 
				<h2>News</h2> 
			</div>
			<!-- row -->
			<div class="row">
				<div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">					
					<div class="col-sm-12">
						<ul>	
							<li><p><strong>2025.07.</strong> <strong>"SMS"</strong> is accepted to <strong>ICCV 2025</strong>. Congratulations!</p></li>
							<li><p><strong>2024.10.</strong> Two papers <strong>"Exo2Ego-V", and "MeshRet" (Spotlight)</strong> are accepted to <strong>NeurIPS 2024</strong>. Congratulations!</p></li>
							<li><p><strong>2024.10.</strong> <strong>Show-1</strong> is accepted to <strong>International Journal of Computer Vision (IJCV)</strong>. Congratulations!</p></li>
							<li><p><strong>2024.08.</strong> I am awarded with <strong>Doctoral Consortium at ECCV 2024,</strong> <strong>"4D-Video Dynamic Scene Reconstruction, Editing, and Generation"</strong>. Congratulations!</p></li>							
							<li><p><strong>2024.07.</strong> Our paper <strong>"MotionDirector: Motion Customization of Text-to-Video Diffusion Models."</strong> is accepted to <strong>ECCV 2024 (oral)</strong>. Congratulations!</p></li>							
							<li><p><strong>2024.04.</strong> Our paper <strong>"Instant3D: Instant Text-to-3D Generation."</strong> is accepted to <strong>International Journal of Computer Vision (IJCV)</strong>. Congratulations!</p></li>
							<li><p><strong>2024.02.</strong> Six papers <strong>DynVideo-E</strong>, <strong>Ego-Exo4D</strong>, <strong>MagicAnimate</strong>, <strong>X-Adapter</strong>, <strong>VideoSwap</strong>, and <strong>VideoLLM-online</strong> are accepted to <strong>Computer Vision and Pattern Recognition (CVPR), 2024</strong>. Congratulations!</p></li>							
							<li><p><strong>2023.12.</strong> I am awarded with <strong>SINGAPORE DATA SCIENCE CONSORTIUM (SDSC) DISSERTATION RESEARCH FELLOWSHIP 2023, recognized as 1 out of 10 most innovative and impactful PhD students focusing on Data Science in Singapore in 2023</strong>. Congratulations!</p></li>							
							<li><p><strong>2023.07.</strong> Two papers <strong>HOSNeRF</strong> and <strong>STPrivacy</strong> are accepted to <strong>International Conference on Computer Vision (ICCV), 2023</strong>. Congratulations!</p></li>
							<li><p><strong>2022.10.</strong> I am awarded with <strong>NeurIPS 2022 Scholar Award</strong> and will attend NeurIPS 2022 conference. Welcome to approach me and chat!</p></li>													
							<li><p><strong>2022.09.</strong> Our paper <strong><i>"DeVRF: Fast Deformable Voxel Radiance Fields for Dynamic Scenes."</i></strong> is accepted by <strong> Thirty-sixth Conference on Neural Information Processing Systems (NeurIPS), 2022</strong>.</p></li>
							<li><p><strong>2021.01.</strong> I am awarded with <strong>President&apos;s Graduate Fellowship (PGF) and start my PhD career in National University of Singapore</strong>.</p></li>							
							<li><p><strong>2020.06.</strong> I am awarded with <strong>Outstanding Graduate</strong>, which is awarded to TOP 8% students in Tsinghua University.</p></li>
							<li><p><strong>2019.10.</strong> I am awarded with <strong>Scholarship of Second Prize in Tsinghua University</strong>, which is awarded to TOP 5% students in Tsinghua University.</p></li>
							<li><p><strong>2019.08.</strong> Our paper <i>"An efficient multibody dynamic model of three-dimensional meshing contacts in helical gear-shaft system and its solution."</i> is accepted by <strong>Mechanism and Machine Theory (SCI source, Q1)</strong>.</p></li>
					</div>
				</div>
			</div>
			<!-- ./row -->		
		</div>
	</section>
	<!-- /.news -->
    
	<!-- publications -->
    <section class="testimonials" id="publications">
		<div class="container">
			<div class="wow bounceInLeft animated" data-wow-delay="0.1s" style="visibility: visible;-webkit-animation-delay: 0.1s; -moz-animation-delay: 0.1s; animation-delay: 0.1s;"> 
				<h2>Selected Publications</h2> 
			</div>
			<!-- row -->
			<div class="row" style="margin-left:10px">
				<div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">					
					<div class="col-sm-3 col-md-3 col-lg-2" style="padding-left:0px;padding-right:0px">
						<div class="avatar">
							<img src="./publications/Exo2Ego-V.png" class="img-responsive img-thumbnail">
						</div>
					</div>
					<div class="col-sm-9 col-md-9 col-lg-9">
						<blockquote style="margin-bottom:5px">
							<h4>
								Exocentric-to-Egocentric Video Generation.
							</h4>
							<p>
								<i><strong>Jia-Wei Liu*</strong></i>, Weijia Mao*, Zhongcong Xu, Jussi Keppo, Mike Zheng Shou. <br>
								<strong>Advances in Neural Information Processing Systems (NeurIPS) 2024</strong>.<br>
								<a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/f5a8b5e5d007e66c929b971c2bc21d76-Paper-Conference.pdf" class="label label-success">PDF</a>
								<a href="./publications/liu2024exocentric.bib" class="label label-primary">BibTex</a>
								<a href="https://github.com/showlab/Exo2Ego-V" class="label label-info">Code</a>
							</p>
						</blockquote>
					</div>
				</div>
			</div>				
			<!-- row -->
			<div class="row" style="margin-left:10px">
				<div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">					
					<div class="col-sm-3 col-md-3 col-lg-2" style="padding-left:0px;padding-right:0px">
						<div class="avatar">
							<img src="./publications/dynvideoe.gif" class="img-responsive img-thumbnail">
						</div>
					</div>
					<div class="col-sm-9 col-md-9 col-lg-9">
						<blockquote style="margin-bottom:5px">
							<h4>
								DynVideo-E: Harnessing Dynamic NeRF for Large-Scale Motion- and View-Change Human-Centric Video Editing.
							</h4>
							<p>
								<i><strong>Jia-Wei Liu</strong></i>, Yan-Pei Cao, Jay Zhangjie Wu, Weijia Mao, Yuchao Gu, Rui Zhao, Jussi Keppo, Ying Shan, Mike Zheng Shou. <br>
								<strong>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2024</strong>.<br>
								<a href="https://arxiv.org/abs/2310.10624" class="label label-success">PDF</a>
								<a href="./publications/liu2023dynvideo.bib" class="label label-primary">BibTex</a>
								<a href="https://showlab.github.io/DynVideo-E/" class="label label-info">Project</a>
							</p>
						</blockquote>
					</div>
				</div>
			</div>				
			<div class="row" style="margin-left:10px">
				<div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">					
					<div class="col-sm-3 col-md-3 col-lg-2" style="padding-left:0px;padding-right:0px">
						<div class="avatar">
							<img src="./publications/hosnerf.gif" class="img-responsive img-thumbnail">
						</div>
					</div>
					<div class="col-sm-9 col-md-9 col-lg-9">
						<blockquote style="margin-bottom:5px">
							<h4>
								HOSNeRF: Dynamic Human-Object-Scene Neural Radiance Fields from a Single Video.
							</h4>
							<p>
								<i><strong>Jia-Wei Liu</strong></i>, Yan-Pei Cao, Tianyuan Yang, Zhongcong Xu, Jussi Keppo, Ying Shan, Xiaohu Qie, Mike Zheng Shou. <br>
								<strong>Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) 2023</strong>.<br>
								<a href="https://arxiv.org/abs/2304.12281" class="label label-success">PDF</a>
								<a href="./publications/liu2023hosnerf.bib" class="label label-primary">BibTex</a>
								<a href="https://showlab.github.io/HOSNeRF" class="label label-info">Project</a>
								<a href="https://github.com/TencentARC/HOSNeRF" class="label label-info">Code</a>
							</p>
						</blockquote>
					</div>
				</div>
			</div>
			<!-- ./row -->																	
			<!-- row -->
			<div class="row" style="margin-left:10px">
				<div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">					
					<div class="col-sm-3 col-md-3 col-lg-2" style="padding-left:0px;padding-right:0px">
						<div class="avatar">
							<img src="./DeVRF/static/images/model_v5.png" class="img-responsive img-thumbnail">
						</div>
					</div>
					<div class="col-sm-9 col-md-9 col-lg-9">
						<blockquote style="margin-bottom:5px">
							<h4>
								DeVRF: Fast Deformable Voxel Radiance Fields for Dynamic Scenes.
							</h4>
							<p>
								<i><strong>Jia-Wei Liu</strong></i>, Yan-Pei Cao, Weijia Mao, Wenqiao Zhang, David Junhao Zhang, Jussi Keppo, Ying Shan, Xiaohu Qie, Mike Zheng Shou. <br>
								<strong>Advances in Neural Information Processing Systems (NeurIPS) 2022</strong>.<br>
								<a href="https://openreview.net/pdf?id=Pu-QtT0h2E" class="label label-success">PDF</a>
								<a href="./publications/liu2022devrf.bib" class="label label-primary">BibTex</a>
								<a href="https://jia-wei-liu.github.io/DeVRF/" class="label label-info">Project</a>
								<a href="https://github.com/showlab/DeVRF" class="label label-info">Code</a>
							</p>
						</blockquote>
					</div>
				</div>
			</div>
			<!-- ./row -->	
			<div class="row" style="margin-left:10px">
				<div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">					
					<div class="col-sm-3 col-md-3 col-lg-2" style="padding-left:0px;padding-right:0px">
						<div class="avatar">
							<img src="./publications/show1.gif" class="img-responsive img-thumbnail">
						</div>
					</div>
					<div class="col-sm-9 col-md-9 col-lg-9">
						<blockquote style="margin-bottom:5px">
							<h4>
								Show-1: Marrying Pixel and Latent Diffusion Models for Text-to-Video Generation.
							</h4>
							<p>
								David Junhao Zhang*, Jay Zhangjie Wu*, <i><strong>Jia-Wei Liu*</strong></i>, Rui Zhao, Lingmin Ran, Yuchao Gu, Difei Gao, Mike Zheng Shou. (* equal contribution) <br>
								<strong>International Journal of Computer Vision, 2024</strong>.<br>
								<a href="https://arxiv.org/abs/2309.15818" class="label label-success">PDF</a>
								<a href="./publications/zhang2023show1.bib" class="label label-primary">BibTex</a>
								<a href="https://showlab.github.io/Show-1/" class="label label-info">Project</a>
								<a href="https://github.com/showlab/Show-1" class="label label-info">Code</a>
							</p>
						</blockquote>
					</div>
				</div>
			</div>				
            <br>
			<!-- ./row -->
			<div class="row" style="margin-left:10px">
				<div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">					
					<div class="col-sm-3 col-md-3 col-lg-2" style="padding-left:0px;padding-right:0px">
						<div class="avatar">
							<img src="./publications/magicanimate.gif" class="img-responsive img-thumbnail">
						</div>
					</div>
					<div class="col-sm-9 col-md-9 col-lg-9">
						<blockquote style="margin-bottom:5px">
							<h4>
								MagicAnimate: Temporally Consistent Human Image Animation using Diffusion Model.
							</h4>
							<p>
								Zhongcong Xu, Jianfeng Zhang, Jun Hao Liew, Hanshu Yan, <i><strong>Jia-Wei Liu</strong></i>, Chenxu Zhang, Jiashi Feng, Mike Zheng Shou. <br>
								<strong>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2024</strong>.<br>
								<a href="https://arxiv.org/abs/2311.16498" class="label label-success">PDF</a>
								<a href="./publications/xu2024magicanimate.bib" class="label label-primary">BibTex</a>
								<a href="https://showlab.github.io/magicanimate/" class="label label-info">Project</a>
								<a href="https://github.com/magic-research/magic-animate" class="label label-info">Code</a>
							</p>
						</blockquote>
					</div>
				</div>
			</div>						
			<!-- row -->
			<!-- ./row -->	
			<div class="row" style="margin-left:10px">
				<div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">					
					<div class="col-sm-3 col-md-3 col-lg-2" style="padding-left:0px;padding-right:0px">
						<div class="avatar">
							<img src="./publications/motiondirector.gif" class="img-responsive img-thumbnail">
						</div>
					</div>
					<div class="col-sm-9 col-md-9 col-lg-9">
						<blockquote style="margin-bottom:5px">
							<h4>
								MotionDirector: Motion Customization of Text-to-Video Diffusion Models.
							</h4>
							<p>
								Rui Zhao, Yuchao Gu, Jay Zhangjie Wu, David Junhao Zhang, <i><strong>Jia-Wei Liu</strong></i>, Weijia Wu, Jussi Keppo, Mike Zheng Shou. <br>
								<strong>European Conference on Computer Vision (ECCV) 2024, oral</strong>.<br>
								<a href="https://arxiv.org/abs/2310.08465" class="label label-success">PDF</a>
								<a href="./publications/zhao2023motiondirector.bib" class="label label-primary">BibTex</a>
								<a href="https://showlab.github.io/MotionDirector/" class="label label-info">Project</a>
								<a href="https://github.com/showlab/MotionDirector" class="label label-info">Code</a>
							</p>
						</blockquote>
					</div>
				</div>
			</div>						
			<!-- row -->
			<div class="row" style="margin-left:10px">
				<div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">					
					<div class="col-sm-3 col-md-3 col-lg-2" style="padding-left:0px;padding-right:0px">
						<div class="avatar">
							<img src="./publications/Overview_Helicalgear_MMT.png" class="img-responsive img-thumbnail">
						</div>
					</div>
					<div class="col-sm-9 col-md-9 col-lg-9">
						<blockquote style="margin-bottom:5px">
							<h4>
								An efficient multibody dynamic model of three-dimensional meshing contacts in helical gear-shaft system and its solution.
							</h4>
							<p>
								<i><strong>Jia-Wei Liu</strong></i>, Jia-Peng Liu, Xuan-Bo Shu, Aki Mikkola, Ge-Xue Ren. <br>
								<strong>Mechanism and Machine Theory (SCI source, Q1)</strong>.<br>
								<a href="https://www.sciencedirect.com/science/article/abs/pii/S0094114X19313898" class="label label-success">PDF</a>
								<a href="./publications/liu2019efficient.bib" class="label label-primary">BibTex</a>
							</p>
						</blockquote>
					</div>
				</div>
			</div>
			<!-- ./row -->
			<!-- row -->
			<div class="row" style="margin-left:10px">
				<div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">					
					<div class="col-sm-3 col-md-3 col-lg-2" style="padding-left:0px;padding-right:0px">
						<div class="avatar">
							<img src="./publications/Overview_Helicalgears_ECCOMAS.png" class="img-responsive img-thumbnail">
						</div>
					</div>
					<div class="col-sm-9 col-md-9 col-lg-9">
						<blockquote style="margin-bottom:5px">
							<h4>
								Dynamic characteristics of helical gear based on Arbitrary Lagrangian Eulerian formulation.
							</h4>
							<p>
								<i><strong>Jia-Wei Liu</strong></i>, Jia-Peng Liu, Jia-Lun Yao, Ge-Xue Ren. <br>
								<strong>ECCOMAS 2019 Multibody Dynamic Conference, Duisburg, Germany</strong>.<br>
								<a href="./publications/EXTENDED_ABSTRACT_ECCOMAS2019.pdf" class="label label-success">PDF</a>
								<a href="./publications/EXTENDED_ABSTRACT_ECCOMAS2019.bib" class="label label-primary">BibTex</a>
							</p>
						</blockquote>
					</div>
				</div>
			</div>
            <br>
			<!-- ./row -->		
		</div>
	</section>
	<!-- /.publications -->
	
	<!-- awards -->
    <section class="testimonials" id="awards">
		<div class="container">
			<div class="wow bounceInLeft animated" data-wow-delay="0.1s" style="visibility: visible;-webkit-animation-delay: 0.1s; -moz-animation-delay: 0.1s; animation-delay: 0.1s;"> 
				<h2>Selected Awards</h2> 
			</div>
			<!-- row -->
			<div class="row">
				<div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">					
					<div class="col-sm-12">
						<ul>
							<li><p><strong>Doctoral Consortium at ECCV 2024, "4D-Video Dynamic Scene Reconstruction, Editing, and Generation", 2024</strong></p></li>							
							<li><p><strong>SINGAPORE DATA SCIENCE CONSORTIUM (SDSC) DISSERTATION RESEARCH FELLOWSHIP 2023 (10000 S$) (1 out of 10 most innovative and impactful PhD students focusing on Data Science in Singapore in 2023), 2023</strong></p></li>
							<li><p><strong>Show Lab Annual Award (4000 S$), National University of Singapore, 2023</strong></p></li>
							<li><p><strong>Research Incentive Award, National University of Singapore, 2023</strong></p></li>
							<li><p><strong>NeurIPS 2022 Scholar Award, 2022</strong></p></li>
							<li><p><strong>President&apos;s Graduate Fellowship (PGF), National University of Singapore, 2021</strong></p></li>
							<li><p><strong>Outstanding Graduate, Tsinghua University (Awarded to top 8% students), 2020</strong></p></li>
							<li><p><strong>Scholarship of Second Prize in Tsinghua University (Awarded to top 5% students), 2019</strong></p></li>
							<li><p><strong>National Scholarship (Awarded to top 1% students in Honors College), 2015</strong></p></li>
						</ul>
					</div>
				</div>
			</div>
			<!-- ./row -->		
		</div>
	</section>
	<!-- /.awards -->

	<!-- academic services -->
    <section class="testimonials" id="academic_services">
		<div class="container">
			<div class="wow bounceInLeft animated" data-wow-delay="0.1s" style="visibility: visible;-webkit-animation-delay: 0.1s; -moz-animation-delay: 0.1s; animation-delay: 0.1s;"> 
				<h2>Academic Attendance and Services</h2> 
			</div>
			<!-- row -->
			<div class="row">
				<div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">					
					<div class="col-sm-12">
						<ul>
							<li><p><strong>Attendance: NeurIPS 2022@New Orleans, Meta Ego4D Meetup 2023@New York, ICCV 2023@Paris, Meta Research Summit 2024@Seattle, CVPR 2024@Seattle, ECCV 2024@Milan, ECCOMAS 2019@Duisburg.</strong></p></li>
							<li><p><strong>Reviewer: IEEE TPAMI, TNNLS, TCSVT, CVPR 2023-2025, ICCV 2023-2025, NeurIPS 2024-2025, ECCV 2024, SIGGRAPH 2024-2025, ICLR 2025, ICML 2025, SIGGRAPH Asia 2025, AAAI 2025, MICCAI 2024-2025, ACMMM 2023-2025, TMLR, etc.</strong></p></li>
						</ul>
					</div>
				</div>
			</div>
			<!-- ./row -->		
		</div>
	</section>
	<!-- /.awards -->	
    
	<!-- footer -->
	<footer id="section-footer">
		<div class="container">
			<div class="row">
				<div class="col-md-12 col-lg-12">
					<div class="wow fadeIn animated" data-wow-delay="0.4s" style="visibility: visible;-webkit-animation-delay: 0.4s; -moz-animation-delay: 0.4s; animation-delay: 0.4s;">
						<div class="btn-circle-scroll">
							<a href="https://jia-wei-liu.github.io#header-banner" class="btn-circle">
								<i class="fa fa-angle-double-up animated"></i>
							</a>
						</div>
					</div>
					<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=n&d=Qxn8qg264YeeX5Ldy0VVn_G3VvB_3x5cMtU0eayqW7g'></script>
					<a href="https://www.easycounter.com/">
						<img src="https://www.easycounter.com/counter.php?jiawei_liu"
						border="0" alt="Web Counter"></a> unique visitors since August 24, 2019.
				</div>
			</div>	
			<div class="columns is-centered">
				<div class="column is-8">
				  <div class="content">
					<p>
					  This website is borrowed from <a
						href="https://liqing-ustc.github.io/">homepage</a>. I am very grateful for his work.
					</p>
				  </div>
				</div>
			  </div>			
		</div>
	</footer>
	<!-- /.footer -->
	
	
	<!-- Core JavaScript Files -->
	<script src="./assets/jquery.min.js.download"></script>
	<script src="./assets/bootstrap.min.js.download"></script>
	<script src="./assets/jquery.easing.min.js.download"></script>	
	<script src="./assets/jquery.scrollTo.js.download"></script>
	<script src="./assets/wow.min.js.download"></script>			<!-- Reveal animation when you scroll by wow.js. It need animate.css library -->
	<!-- Custom Theme JavaScript -->
	<script src="./assets/custom.js.download"></script>




<div id="point-jawn" style="z-index: 2147483647;"></div></body></html>
